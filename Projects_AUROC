# 1. Chuẩn bị và xử lý dữ liệu

import pandas as pd

# 1.1: 16S rRNA Data: Tạo bảng đặc trưng ASV hoặc OTU
data = pd.read_csv('16s_data.csv')
asv_feature_table = data.groupby('ASV').sum()

# 1.2: Shotgun Metagenomics Data: Tạo bảng đặc trưng từ dữ liệu gene chức năng
shotgun_data = pd.read_csv('shotgun_data.csv')
gene_feature_table = shotgun_data.groupby('GeneFunction').sum()

# 1.3: Metadata: Tích hợp thông tin lâm sàng
metadata = pd.read_csv('metadata.csv')
full_dataset = pd.merge(asv_feature_table, gene_feature_table, on='SampleID')
full_dataset = pd.merge(full_dataset, metadata, on='SampleID')


# 2. Xây dựng và chọn lọc đặc trưng

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# 2.1: Chọn lọc đặc trưng: Sử dụng Random Forest Feature Importance
X = full_dataset.drop(columns=['DiseaseStatus'])
y = full_dataset['DiseaseStatus']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Chuẩn hóa dữ liệu sau khi áp dụng log-transformation
X_train_log = np.log1p(X_train)
X_test_log = np.log1p(X_test)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_log)
X_test_scaled = scaler.transform(X_test_log)

# Huấn luyện Random Forest
clf = RandomForestClassifier()
clf.fit(X_train_scaled, y_train)

# Lấy độ quan trọng của đặc trưng và in ra
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]
print("Feature ranking:")
for f in range(X_train.shape[1]):
    print(f"{f + 1}. Feature {indices[f]} ({importances[indices[f]]})")


# 3: Xây dựng mô hình dự đoán

# 3.1: Huấn luyện mô hình với Random Forest
clf.fit(X_train_scaled, y_train)

# 3.2: Cross-validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(clf, X, y, cv=5)
print(f"Cross-validation scores: {scores}")

# 3.3: Huấn luyện mô hình và thực hiện Random Search
from sklearn.model_selection import RandomizedSearchCV
param_dist = {
    'n_estimators': [50, 100, 200],
    'max_features': ['auto', 'sqrt'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, random_state=42, cv=3)
random_search.fit(X_train_scaled, y_train)

print(f"Best parameters: {random_search.best_params_}")


# 4. Đánh giá mô hình với AUROC

from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt

# 4.1: Dự đoán và vẽ đường cong ROC
y_pred = random_search.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()

# 4.2: Kiểm tra độ nhạy và độ đặc hiệu
cm = confusion_matrix(y_test, random_search.predict(X_test_scaled))
tn, fp, fn, tp = cm.ravel()
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
#In ra kết quả
print(f"Sensitivity: {sensitivity}")
print(f"Specificity: {specificity}")
